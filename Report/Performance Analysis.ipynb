{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use Hamming distance to analyse our models. The hamming distance of two binary arrays $ x $ and $ y $ is the number of positions at which the corresponding symbols are different: \n",
    "\n",
    "$$H(X,Y) = \\sum\\limits_{i=1}^n \\mathbb{1}(x_i = y_i) $$\n",
    "\n",
    "We decided to use this metric as it is uniform across the models and gives insight into accuracy of the model. Some of the models predicted the attack type whereas others predicted normal vs non-normal behaviour which means we had to find a standardised test across the two types of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamming Distance</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Matt</td>\n",
       "      <td>3</td>\n",
       "      <td>99.993928%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hamming Distance    Accuracy\n",
       "Matt                 3  99.993928%"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_matt = pd.read_csv('https://github.com/Galeforse/DST-Assessment-01/raw/main/Data/test_predictions_matt.csv')\n",
    "test_labels = pd.read_csv('https://github.com/Galeforse/DST-Assessment-01/raw/main/Data/test_labels.csv')\n",
    "\n",
    "pred_matt = np.array(pred_matt['0'])\n",
    "test_labels = np.array(test_labels['label'])\n",
    "\n",
    "hamm_dist_matt = distance.hamming(pred_matt,test_labels)\n",
    "accuracy_matt = 1 - hamm_dist_matt\n",
    "hamm_dist_matt = int(hamm_dist_matt * len(test_labels))\n",
    "\n",
    "pd.DataFrame([[hamm_dist_matt, \"{:.6%}\".format(accuracy_matt)]], columns = ['Hamming Distance', 'Accuracy'], index = ['Matt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alex - KNN (K Nearest Neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamming Distance</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>886</td>\n",
       "      <td>98.20%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hamming Distance Accuracy\n",
       "0               886   98.20%"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' R code to get the Hamming distance for Alex's model's result'''\n",
    "## library(class)\n",
    "## library(caret)\n",
    "\n",
    "# pr1 <- knn(KTT_train,KTT_test,cl=KTT_target_category,k=1, use.all=FALSE)\n",
    "## [...]\n",
    "## [...]\n",
    "# pr37 <- knn(KTT_train,KTT_test,cl=KTT_target_category,k=1, use.all=FALSE)\n",
    "\n",
    "# h<- vector(length=37)\n",
    "# h[1]<-hamming.distance(as.vector(pr1), kt$Behaviour[1:1333])\n",
    "## [...]\n",
    "## [...]\n",
    "# h[37]<-hamming.distance(as.vector(pr37), kt$Behaviour[46790:48122])\n",
    "\n",
    "# m <- sum(h) ## The total Hamming Distance\n",
    "\n",
    "# h <- -h\n",
    "# h<- h+1333\n",
    "# h<- h/1333\n",
    "# summary(h) # mean = 98.2% accuracy. ## The accuracy\n",
    "\n",
    "pred_alex_df = pd.read_csv('https://github.com/Galeforse/DST-Assessment-01/raw/main/Data/KNN-Performance.csv')\n",
    "\n",
    "hamm_dist_alex = pred_alex_df.iat[0,0]\n",
    "accuracy_alex = pred_alex_df.iat[0,1]\n",
    "\n",
    "pred_alex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamming Distance</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Luke</td>\n",
       "      <td>1391</td>\n",
       "      <td>97.184325%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hamming Distance    Accuracy\n",
       "Luke              1391  97.184325%"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_luke = pd.read_csv('https://github.com/Galeforse/DST-Assessment-01/raw/main/Data/Y_pred_Luke.csv')\n",
    "test_labels = pd.read_csv('https://github.com/Galeforse/DST-Assessment-01/raw/main/Data/Y_test_Luke.csv')\n",
    "\n",
    "pred_luke = np.array(pred_luke['0'])\n",
    "test_labels = np.array(test_labels['label'])\n",
    "\n",
    "hamm_dist_luke = distance.hamming(pred_luke,test_labels)\n",
    "accuracy_luke = 1 - hamm_dist_luke\n",
    "hamm_dist_luke = int(hamm_dist_luke * len(test_labels))\n",
    "\n",
    "pd.DataFrame([[hamm_dist_luke, \"{:.6%}\".format(accuracy_luke)]], columns = ['Hamming Distance', 'Accuracy'], index = ['Luke'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gabriel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have two trained models, one using basic Logistic Regression and the other using `GridSearchCV` with cross-validation. Despite the Grid version taking almost 80 times as long to train as the basic model, the actual increase in accuracy was rather small, especially comparing the hamming distance of the two, with that many data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamming Distance</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gabe Grid</td>\n",
       "      <td>73</td>\n",
       "      <td>99.852233%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gabe Basic</td>\n",
       "      <td>76</td>\n",
       "      <td>99.846160%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hamming Distance    Accuracy\n",
       "Gabe Grid                 73  99.852233%\n",
       "Gabe Basic                76  99.846160%"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gabe_grid = pd.read_csv('https://github.com/Galeforse/DST-Assessment-01/raw/main/Data/grid_y_pred_gabe.csv')\n",
    "pred_gabe_basic = pd.read_csv('https://github.com/Galeforse/DST-Assessment-01/raw/main/Data/reg_y_pred_gabe.csv')\n",
    "test_labels = pd.read_csv('https://github.com/Galeforse/DST-Assessment-01/raw/main/Data/y_test_gabe.csv')\n",
    "\n",
    "pred_gabe_grid = np.array(pred_gabe_grid['0'])\n",
    "pred_gabe_basic = np.array(pred_gabe_basic['0'])\n",
    "test_labels = np.array(test_labels['0'])\n",
    "\n",
    "hamm_dist_gabe = distance.hamming(pred_gabe_grid,test_labels)\n",
    "accuracy_gabe = 1 - hamm_dist_gabe\n",
    "hamm_dist_gabe = int(hamm_dist_gabe * len(test_labels))\n",
    "\n",
    "hamm_dist_gabe2 = distance.hamming(pred_gabe_basic,test_labels)\n",
    "accuracy_gabe2 = 1 - hamm_dist_gabe2\n",
    "hamm_dist_gabe2 = int(hamm_dist_gabe2 * len(test_labels))\n",
    "\n",
    "pd.DataFrame([[hamm_dist_gabe, \"{:.6%}\".format(accuracy_gabe)],[hamm_dist_gabe2, \"{:.6%}\".format(accuracy_gabe2)]], columns = ['Hamming Distance', 'Accuracy'], index = ['Gabe Grid','Gabe Basic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamming Distance</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Matt</td>\n",
       "      <td>3</td>\n",
       "      <td>99.993928%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Alex</td>\n",
       "      <td>886</td>\n",
       "      <td>98.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Luke</td>\n",
       "      <td>1391</td>\n",
       "      <td>97.184325%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gabriel</td>\n",
       "      <td>73</td>\n",
       "      <td>99.852233%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Hamming Distance    Accuracy\n",
       "Matt                    3  99.993928%\n",
       "Alex                  886      98.20%\n",
       "Luke                 1391  97.184325%\n",
       "Gabriel                73  99.852233%"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[hamm_dist_matt, \"{:.6%}\".format(accuracy_matt)],[hamm_dist_alex, accuracy_alex],[hamm_dist_luke, \"{:.6%}\".format(accuracy_luke)],[hamm_dist_gabe, \"{:.6%}\".format(accuracy_gabe)]], columns = ['Hamming Distance', 'Accuracy'], index = ['Matt', 'Alex', 'Luke', 'Gabriel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report reflects the results we obtained from running our models. Matt ran a random forest model which had an accuracy of $99.99\\%$, Alex ran a k-NN model with k=1 and had an accuracy of $98.20\\%$, Luke ran a Bayesian model which had an accuracy of $97.18\\%$ and Gabriel ran a Linear Regression model and obtain a $99.85\\%$ accuracy. Thus we have a scoring of:\n",
    "1. Matt\n",
    "2. Gabriel\n",
    "3. Alex\n",
    "4. Luke\n",
    "\n",
    "All of the models give very accurate results of $>97\\%$. The most accurate model is the random forest for this data and produces the most accurate results. This may be due to the ability of a random forest to handle all the features we have and not having to work on a reduced space which the k-nn model had to.\n",
    "\n",
    "The most difficult process for all of our models was the data processing to allow the models to run on the data. This involved:\n",
    "- re-labelling the data to 0's and 1's to allow us to model normal vs non-normal data since most of the models are binary\n",
    "- normalising data \n",
    "- creating dummy variables to allow us to run models on categorical features.\n",
    "\n",
    "The models were then run on training data to develop them and allow them to learn about the differences between the attacks and the normal data and then tested on teh 10% test split we created. Further tests were conducted on some of us with testing on external text data such as the extra KD99 test data and also testing on non-binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
