{"cells":[{"metadata":{},"cell_type":"markdown","source":"Here I go through the code used to transform the data procured from [here](https://github.com/Galeforse/DST-Assessment-01/blob/main/Matt%20Corrie/KD99_corrected.csv%202.zip). \nWe intend to use a k-fold Cross Validation method on the dataset, and let k=10.\nBecause of that, we have sampled the data in 10 folds: 9 will be used as training data, and 1 will be used for testing.\n\n_All data is shuffled, so that we can properly test whether results will be conclusive and not just incidental when moving on to the test data after we're done training on the (90%) portion_\n\nCode below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# setwd(\"D://R-4.0.2//ExcelWorks\")\n                ## I saved the file Matt posted exactly as he posted it, i.e. \"KD99.csv\"\n                ## If for some reason you saved it differently, and you want to run this code yourself\n                ## make sure to impose the adequate changes. There's **no reason to actually run this code**,\n                ## I'm only mostly posting it for reference.\n\nkd <- read.csv(file = \"KD99.csv\", header = T)\nkd <- kd[sample(nrow(kd)),] # Shuffle the data around\nkd.test <- tail(kd, 49402) # The data is already shuffled, so whatever segment we pick is fine.\nkd.train <- head(kd, 494021 - 49402)\n\tfolds <- cut(seq(1,nrow(kd.train)),breaks=9,labels=FALSE)\n\tkdd <- cbind(kd.train, folds)\n\t# s <- split(kdd, f = kdd$folds)\nwrite.csv(kd.test, file = \"kd_test.csv\") ## This is how I obtaind \"kd_test.csv\"\nwrite.csv(kdd, file = \"kd_train.csv\") ## This is how I obtained \"kd_train.csv\"\n    \n        ## If you want to work with 9 separate datasets, shouldn't be too hard\n\t## for(i in 1:9) {\n\t##\t... # Since it's only 9 datapoints, can work on each individually\n\t##\t... \t# if you want\n\t##\t}\n\t\t\n        ## Alternative for folding:\nlibrary(caret) # Requires install.packages(caret)\nflds <- createFolds(kd, k = 10, list = TRUE, returnTrain = FALSE)\nnames(flds)[1] <- \"train\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training data is a 90% portion of the initial dataset as promised, but shuffled around. I briefly thought of 2 alternatives, if this format isn't exactly suitable for your choice of data modelling:\n\n1) Do exactly the above, but without shuffling the data around. This might be useful if your desired modelling technique is concerned with predicting future activity based on really good knowledge of the past one. To do that, just remove the sample bit.\n\n2) Change the value of k. I'm not sure right now why you would want k!=10 for this particular dataset, since k=10 seems to be optimal -- but if you want to, the only place that needs addressing is \"breaks=...\" changed from \"breaks=9\" on row 11 when defining the variable folds. \n\n**Important**\n\nI left the training data as a single file, partitioned into 9 folds as promised. I did this because different methods may work better on this. If you'd, however, prefer working on 9 different files it's fairly easy to separate them up. Either way, the folding has been assigned already in \"kd_train.csv\", you're only left to split it however you wish. One method is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"## kdd <- read.csv(file = \"kd_train.csv\", header = T)\ns <- split(kdd, f = kdd$folds)\n## print(head(s,2)) ### Don't do this, it's huge. Only if you really want to check what the splitting looks like","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}